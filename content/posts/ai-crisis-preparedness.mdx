---
title: "AI Crisis Preparedness: What Humanitarian Systems Can Teach Us"
date: "2025-01-15"
excerpt: "Lessons from humanitarian field coordination offer underexplored insights for designing AI incident response frameworks that actually work under pressure."
tags:
  - AI Governance
  - Humanitarian Tech
---

The humanitarian system has spent decades learning how to coordinate under crisis conditions — fragmented information, competing priorities, infrastructure collapse, and the constant pressure of decisions that carry life-or-death consequences. These are not abstract challenges. They are operational realities that the Emergency Telecommunications Cluster, the logistics coordination bodies, and the inter-agency frameworks of the UN system confront every time a crisis unfolds.

## The Parallels Are Structural, Not Metaphorical

When we talk about AI incident response, we tend to reach for analogies from cybersecurity or nuclear safety. These are useful but incomplete. The humanitarian coordination model offers something different: a framework for managing multi-stakeholder crises where no single actor has full authority, information is incomplete, and the cost of coordination failure is borne by the most vulnerable.

This maps more closely onto the likely dynamics of serious AI incidents than we might initially assume. Consider:

- **No single point of control.** In a humanitarian emergency, no one organization runs the response. The cluster system works precisely because it coordinates across agencies with different mandates, capabilities, and political constraints. AI governance will face the same fragmentation — multiple national regulators, international bodies, and private actors, none with unilateral authority.

- **Information asymmetry under time pressure.** Field coordination operates in environments where you never have the full picture. Decisions must be made with partial data, revised as new information arrives, and communicated across organizations with different reporting standards. AI incident response will demand the same capacity for structured decision-making under uncertainty.

- **Pre-positioned capabilities matter more than reactive ones.** The most effective humanitarian responses are those where coordination mechanisms, communication infrastructure, and decision-making protocols exist *before* the crisis hits. The same principle should apply to AI governance — we need standing institutions, not ad hoc committees assembled after the fact.

## What This Means for AI Governance Design

If we take these parallels seriously, several implications follow for how we design AI oversight and incident response systems:

First, we need to invest in **interoperability** — not just technical interoperability between AI systems, but institutional interoperability between the bodies responsible for governing them. The humanitarian system learned this the hard way after repeated coordination failures in the 1990s and early 2000s.

Second, **tabletop exercises and simulation-based preparedness** should become standard practice in AI governance circles. The humanitarian community runs these regularly. The AI governance community has barely begun.

Third, we should study the conditions under which humanitarian coordination has *failed* — the cases where the cluster system broke down, where information sharing collapsed, where political dynamics overrode technical coordination. These failure modes are instructive for understanding the vulnerabilities of any multi-stakeholder AI governance framework.

---

*This is an area I'm actively researching and writing about. If you're working on AI incident response frameworks or crisis preparedness in governance contexts, I'd welcome the conversation.*
